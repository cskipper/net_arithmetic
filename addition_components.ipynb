{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks, while quite adept at addressing some complex problems which lack procedural solutions (e.g., image recognition...), have not yet developed sufficient capabilities to reliably perform rather basic tasks. For example, it is a non-trivial task to train a network to perform addition of two arbitrary numbers.\n",
    "\n",
    "Now, when adding, humans perform a number of subtasks as part of the overall algorithm used. For example:\n",
    "\n",
    "- Numbers are decomposed into individual digits. \n",
    "- Digits of the two numbers are paired based on corresponding places.\n",
    "- Digits are added.\n",
    "- A determination is made whether digit addition results in a carry-over to the next place.\n",
    "- This sequence is iterated until all digits in both numbers have been processed.\n",
    "- Output digits are concatenated into a final answer.\n",
    "\n",
    "Furthermore, basic addition of single digits involves a careful iteration of counting out successive numbers to reach the right answer.\n",
    "\n",
    "So, even though we may consider addition to be basic, there is a fair amount of complexity to it. We easily forget how long it took to learn full addition of arbitrary sized numbers in elementary school -- this was something that was neatly fed to us in bite-sized chunks over a period of time in elementary.\n",
    "\n",
    "If it takes a human (who has about 100B neurons) that much progression to learn addition, it's impractical to think a neural net (regardless of the types of nodes used) could learn the process in full generality from a single set of training data. A possibly better approach would be to decompose the overall algorithm into atomic subtasks, train on these tasks, and find ways to allow networks to compose and iterate using previously learned tasks. \n",
    "\n",
    "Graves (https://arxiv.org/pdf/1603.08983v4.pdf) has started to address providing networks with the capability to learn flexible iteration strategies and Neelakantan et al (https://arxiv.org/pdf/1511.04834v3.pdf) have proposed a method for allowing networks to learn by composing available functions. This work aims to extend utilize and extend these approaches to develop a network architecture capable of learning atomic tasks and using these tasks to learn more complex tasks.\n",
    "\n",
    "This present notebook provides exploratory analysis of the efficacy of LSTM-based networks in performing some of the atomic tasks involved in addition to gauge the computational resources required for the overall project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM-based model for concatenation with hidden layer size 10:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 22s - loss: 4.9081 - acc: 0.7266    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 22s - loss: 3.2336 - acc: 0.9772    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 24s - loss: 2.1645 - acc: 0.8899    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 24s - loss: 1.6426 - acc: 0.8036    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 24s - loss: 1.4584 - acc: 0.6994    \n",
      "Training LSTM-based model for concatenation with hidden layer size 20:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 29s - loss: 4.0203 - acc: 0.8379    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 27s - loss: 1.6602 - acc: 0.7219    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 29s - loss: 1.4060 - acc: 0.5189    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 27s - loss: 1.3957 - acc: 0.5072    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 28s - loss: 1.3927 - acc: 0.5040    \n",
      "Training LSTM-based model for concatenation with hidden layer size 30:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 32s - loss: 3.0938 - acc: 0.7963    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 31s - loss: 1.4117 - acc: 0.5176    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 31s - loss: 1.3954 - acc: 0.5036    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 30s - loss: 1.3922 - acc: 0.5012    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 30s - loss: 1.3906 - acc: 0.5008    \n",
      "Training LSTM-based model for successor with hidden layer size 10:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 19s - loss: 1.4958 - acc: 0.6773    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 18s - loss: 0.0936 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 18s - loss: 0.0023 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 19s - loss: 6.1702e-05 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 18s - loss: 1.5712e-06 - acc: 1.0000    \n",
      "Training LSTM-based model for successor with hidden layer size 20:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 21s - loss: 0.8810 - acc: 0.8714    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 19s - loss: 4.4042e-04 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 20s - loss: 2.3420e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 20s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 20s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for successor with hidden layer size 30:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 23s - loss: 0.6212 - acc: 0.9343    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 22s - loss: 8.3637e-07 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 22s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 22s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 22s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for predecessor with hidden layer size 10:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 20s - loss: 1.5328 - acc: 0.5956    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 19s - loss: 0.1043 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 19s - loss: 0.0024 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 19s - loss: 5.4999e-05 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 19s - loss: 1.7060e-06 - acc: 1.0000    \n",
      "Training LSTM-based model for predecessor with hidden layer size 20:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 21s - loss: 0.8685 - acc: 0.9354    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 20s - loss: 3.1901e-04 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 20s - loss: 1.7285e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 20s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 20s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for predecessor with hidden layer size 30:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 23s - loss: 0.6132 - acc: 0.9624    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 22s - loss: 8.0322e-07 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 22s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 22s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 22s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for extraction with hidden layer size 30:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 30s - loss: 1.6019 - acc: 0.3912    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 29s - loss: 0.6124 - acc: 0.7736    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 29s - loss: 0.0184 - acc: 0.9985    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 29s - loss: 2.5237e-05 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 29s - loss: 1.2311e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for extraction with hidden layer size 60:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 40s - loss: 1.1935 - acc: 0.5087    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 39s - loss: 0.1124 - acc: 0.9710    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 39s - loss: 8.8561e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 39s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 40s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for extraction with hidden layer size 90:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 52s - loss: 1.0520 - acc: 0.5662    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 51s - loss: 0.0161 - acc: 0.9978    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 52s - loss: 1.1933e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 53s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 55s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for equality with hidden layer size 10:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 26s - loss: 0.5970 - acc: 0.8982    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 24s - loss: 0.3166 - acc: 0.9003    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 24s - loss: 0.1444 - acc: 0.9476    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 24s - loss: 0.0027 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 24s - loss: 1.5284e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for equality with hidden layer size 20:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 30s - loss: 0.4648 - acc: 0.8979    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 28s - loss: 0.0911 - acc: 0.9644    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 28s - loss: 2.0907e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 28s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 28s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for equality with hidden layer size 30:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 33s - loss: 0.4147 - acc: 0.8991    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 31s - loss: 0.0676 - acc: 0.9744    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 32s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 33s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 33s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for addition with hidden layer size 10:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 29s - loss: 2.2781 - acc: 0.1224    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 27s - loss: 1.6042 - acc: 0.3189    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 27s - loss: 0.9075 - acc: 0.7630    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 31s - loss: 0.2639 - acc: 0.9845    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 26s - loss: 0.0333 - acc: 1.0000    \n",
      "Training LSTM-based model for addition with hidden layer size 20:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 33s - loss: 2.1132 - acc: 0.1679    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 30s - loss: 0.9402 - acc: 0.7283    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 29s - loss: 0.0399 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 35s - loss: 3.4725e-05 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 30s - loss: 1.2999e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for addition with hidden layer size 30:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 34s - loss: 1.8598 - acc: 0.3313    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 32s - loss: 0.0854 - acc: 0.9997    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 33s - loss: 3.5961e-06 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 35s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 36s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for carry with hidden layer size 10:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 30s - loss: 0.7290 - acc: 0.7012    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 29s - loss: 0.0182 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 28s - loss: 7.9265e-06 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 27s - loss: 1.1923e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 27s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for carry with hidden layer size 20:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 32s - loss: 0.4385 - acc: 0.8472    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 30s - loss: 6.8849e-05 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 31s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 32s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 31s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Training LSTM-based model for carry with hidden layer size 30:\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 36s - loss: 0.2708 - acc: 0.9038    \n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 33s - loss: 2.4296e-06 - acc: 1.0000    \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 34s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 35s - loss: 1.1921e-07 - acc: 1.0000    \n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 36s - loss: 1.1921e-07 - acc: 1.0000    \n"
     ]
    }
   ],
   "source": [
    "# List of rule-generating functions which will be used to train models\n",
    "flist = [concatenation, successor, predecessor, extraction, equality, addition, carry]\n",
    "\n",
    "models = {} \n",
    "history = {}\n",
    "best_model = {}\n",
    "\n",
    "for j, f in enumerate(flist):\n",
    "    x_train, y_train = inflate(f(),50000)\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    in_dim = len(x_train[0][0])\n",
    "    timesteps = len(x_train[0])\n",
    "    out_dim = len(y_train[0])\n",
    "    max_scale = 3\n",
    "    epochs = 5\n",
    "\n",
    "    best_loss = 1.0\n",
    "    best = None\n",
    "    models[f] = []\n",
    "    history[f] = []\n",
    "\n",
    "    for i in range(max_scale):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(in_dim*(i+1), return_sequences=True, input_shape=(timesteps, in_dim)))  \n",
    "        model.add(LSTM(in_dim*(i+1), return_sequences=True))  \n",
    "        model.add(LSTM(in_dim*(i+1)))\n",
    "        model.add(Dense(out_dim, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        print 'Training LSTM-based model for {} with hidden layer size {}:'.format(f.__name__,in_dim*(i+1))\n",
    "        history[f].append(model.fit(x_train, y_train, batch_size=64, nb_epoch=epochs))\n",
    "        models[f].append(model)\n",
    "        if history[f][i].history['loss'][epochs-1] < best_loss:\n",
    "            best_loss = history[f][i].history['loss'][epochs-1]\n",
    "            best = i\n",
    "    best_model[f] = best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras",
   "language": "python",
   "name": "tandk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
